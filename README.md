# TextMiningAndInjuryClassification
Last Project Update : December 2022



Abstract:
In injury surveillance, different aspects of an injury event are captured using injury codes. This task is usually done by human coders and then the data is used for statistical analysis. This project aims to identify various elements of injury surveillance like cause of injury, product involved, nature of injury and so on from the textual narrative of the injury using machine learning and natural language processing approaches.

Human coded data is usually assigned from hospital logs of injury description. It takes months for the data to be available for statistical analysis. This time gap is substantial and many injuries can be prevented if we know about the features of injuries like cause, product involved and nature of injury sooner. Moreover, injuries that are not treated by the hospitals are never logged but can be found as textual narratives in the form of reviews online. This is useful for assimilating more data and making accurate decisions. Hence, by using machine learning and natural language processing, we aim to solve the aforementioned problems which contribute to Global Health by borrowing the frameworks of computer science.

The research process can be broadly classified into three parts: getting data, applying machine learning techniques, concluding the output.
The main purpose of this research is to contribute to Global Health, hence the data and conclusions fall under it, and the process by which we make these conclusions falls under the domain of computer science. The framework used to process all data and derive conclusions uses machine learning and natural language processing techniques.
By having a clear vision about the purpose of this research, a balance is maintained as only the process and the methodology is borrowed from computer science, the data and conclusions are consistent within the domain of global health.

There are a few limitations of using machine learning to classify injury narratives. Firstly, the data is not ubiquitous. Data about certain products cannot be found in textual narratives. Moreover, textual narratives are susceptible to ambiguity in phrasing, choice of words and sarcasm which causes machine learning models to lose accuracy.
To improve the efficacy of models, substantial manual coding can be required. It is difficult for an algorithm on its own to be able to assign classifications in all categories with the same level of confidence and very difficult to improve the accuracy of computer-generated codes for the small categories.
